# -*- coding: utf-8 -*-
"""pracml1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1moPhHUuFcSDern2sOi0Ibo7DCArvPVKh
"""

import torch
import os
import numpy as np
import pandas as pd
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch import nn
import torch.nn.functional as f
import matplotlib.pyplot as plt

device = (
    "cuda"
    if torch.cuda.is_available()
    else "mps"
    if torch.backends.mps.is_available()
    else "cpu"
)
print(f"Using {device} device")

mit_train = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv', header=None)
mit_train = mit_train.values
mit_labels = mit_train[:,-1]

# Data for the pie chart
sizes = [len(np.where(mit_labels==0)[0])/mit_train.__len__(), #0 proportion
         len(np.where(mit_labels==1)[0])/mit_train.__len__(), #1 proportion
         len(np.where(mit_labels==2)[0])/mit_train.__len__(), #2 proportion
         len(np.where(mit_labels==3)[0])/mit_train.__len__(), #3 proportion
         len(np.where(mit_labels==4)[0])/mit_train.__len__()] #4 proportion

labels = ['N', 'S', 'V', 'F', 'Q']  # Labels for each wedge

# Create the pie chart
plt.pie(sizes, labels=labels, autopct='%1.1f%%')

# Set aspect ratio to be equal so that pie is drawn as a circle
plt.axis('equal')

# Display the chart
# plt.show()
plt.savefig('/kaggle/working/dist0.jpg', dpi=400)

class MitData:
    def __init__(self, csv_path, drop):
        df = pd.read_csv(csv_path, header=None)
        df = df.values
        df = df[drop:, :]
        self.labels = df[:, -1]
        self.datas = df[:, :-1]

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        label = torch.LongTensor([self.labels[idx]])
        data = torch.Tensor(self.datas[idx]).unsqueeze(0)
        return data, label

mit_test = MitData('/kaggle/input/heartbeat/mitbih_test.csv', 16500)
mit_train = MitData('/kaggle/input/heartbeat/mitbih_train.csv', 67000)

# Data for the pie chart
sizes = [len(np.where(mit_train.labels==0)[0])/mit_train.__len__(), #0 proportion
         len(np.where(mit_train.labels==1)[0])/mit_train.__len__(), #1 proportion
         len(np.where(mit_train.labels==2)[0])/mit_train.__len__(), #2 proportion
         len(np.where(mit_train.labels==3)[0])/mit_train.__len__(), #3 proportion
         len(np.where(mit_train.labels==4)[0])/mit_train.__len__()] #4 proportion

labels = ['N', 'S', 'V', 'F', 'Q']  # Labels for each wedge

# Create the pie chart
plt.pie(sizes, labels=labels, autopct='%1.1f%%')

# Set aspect ratio to be equal so that pie is drawn as a circle
plt.axis('equal')

# Display the chart
# plt.show()
plt.savefig('/kaggle/working/dist.jpg', dpi=400)

# Data for the pie chart
sizes = [len(np.where(mit_test.labels==0)[0])/mit_test.__len__(), #0 proportion
         len(np.where(mit_test.labels==1)[0])/mit_test.__len__(), #1 proportion
         len(np.where(mit_test.labels==2)[0])/mit_test.__len__(), #2 proportion
         len(np.where(mit_test.labels==3)[0])/mit_test.__len__(), #3 proportion
         len(np.where(mit_test.labels==4)[0])/mit_test.__len__()] #4 proportion

labels = ['N', 'S', 'V', 'F', 'Q']  # Labels for each wedge

# Create the pie chart
plt.pie(sizes, labels=labels, autopct='%1.1f%%')

# Set aspect ratio to be equal so that pie is drawn as a circle
plt.axis('equal')

# Display the chart
plt.show()

class ResBlock(nn.Module):
    def __init__(self):
        super().__init__()

        self.conv1 = nn.Conv1d(32, 32, 5, padding='same')
        self.conv2 = nn.Conv1d(32, 32, 5, padding='same')
        self.pool = nn.MaxPool1d(5, 2)

    def forward(self, x):
        output = f.relu(self.conv1(x))
        output = self.conv2(output)
        output = f.relu(output+x)
        output = self.pool(output)
        return output

class Net(nn.Module):
    def __init__(self):
        super().__init__()

        self.conv = nn.Conv1d(1, 32, 5, padding='same')
        self.res = nn.Sequential(
            ResBlock(),
            ResBlock(),
            ResBlock(),
            ResBlock(),
            ResBlock()
        )
        self.fc1 = nn.Linear(64, 32)
        self.fc2 = nn.Linear(32, 5)

    def forward(self, x):
        output = self.conv(x)
        output = self.res(output)
        output = nn.Flatten()(output)
        output = f.relu(self.fc1(output))
        output = f.softmax(self.fc2(output))
        return output

mit_model = Net().to(device)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(mit_model.parameters(), lr=1e-3)

BATCH = 64
EPOCH = 50

generator1 = torch.Generator().manual_seed(42)
mit_train, mit_val = torch.utils.data.random_split(mit_train, [0.8, 0.2], generator=generator1)

mit_test_loader = DataLoader(mit_test, batch_size=1)
mit_train_loader = DataLoader(mit_train, batch_size=BATCH, shuffle=True)
mit_val_loader = DataLoader(mit_val, batch_size=BATCH, shuffle=True)

def save_checkpoint(state, is_best, epoch):
    torch.save(state[f'state_dict'], f'/kaggle/working/{epoch}_last.pth')
    if is_best:
        print('Found best')
        torch.save(state[f'state_dict'], f'/kaggle/working/{epoch}_best.pth')

from tqdm.notebook import tqdm
import pandas as pd

def train(model, epoch, train_dataloader, val_dataloader, optimizer, loss_fn):
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, min_lr=1e-9,verbose=True)
    best_acc = 0
    result = {'epoch':[] ,'train_loss_total':[], "val_loss_total":[], 'acc_total':[]}

    for e in range(EPOCH):
        # Training loop
        print(f"Epoch {e+1}")
        result['epoch'].append(e+1)
        print('Train-----')
        loss_epoch = 0
        model.train()

        for batch_data, batch_labels in tqdm(train_dataloader):
            batch_data = batch_data.to(device)

            # Forward pass
            label = batch_labels.to(device).squeeze()
            output = model(batch_data)

            # Optim
            optimizer.zero_grad()
            loss = loss_fn(output, label)
            loss_epoch += loss.item()
            loss.backward()
            optimizer.step()


        # Combined loss
        loss_epoch /= len(train_dataloader)
        result['train_loss_total'].append(loss_epoch)

        print('Loss: ', loss_epoch)

        # Vaidating
        size = len(val_dataloader.dataset)
        num_batches = len(val_dataloader)
        model.eval()


        test_loss = 0
        correct = 0

        with torch.no_grad():
            print('Val------')
            for X, y in tqdm(val_dataloader):

                X = X.to(device)
                pred = model(X)

                label = y.to(device).squeeze()

                test_loss += loss_fn(pred, label).item()

                correct += (pred.argmax(1) == label).type(torch.float).sum().item()

        test_loss /= num_batches
        correct /= size
        scheduler.step(test_loss)

        result['val_loss_total'].append(test_loss)
        result['acc_total'].append(correct)

        # remember best acc@ and save checkpoint
        is_best = correct > best_acc
        if is_best:
            print('Good')
        best_acc = max(correct, best_acc)
        save_checkpoint({
            f'state_dict': model.state_dict(),
        }, is_best, epoch)



        print(f"""Val Error:
        Accuracy: {(100*correct)}%
        Avg loss: {test_loss}
        """)
    r = pd.DataFrame(result)
    r.to_csv(f'/kaggle/working/result.csv')
    return result

mit_result = train(mit_model, EPOCH, mit_train_loader, mit_val_loader, optimizer, loss_fn)

result = pd.read_csv('/kaggle/working/result.csv')
plt.plot(result['epoch'], result['train_loss_total'], color='red', label='Train loss')
plt.plot(result['epoch'], result['val_loss_total'], color='blue', label='Val loss')
plt.legend()
plt.show()

plt.plot(result['epoch'], result['acc_total'], color='g', label='Accuracy')
plt.legend()
plt.show()

from tqdm import tqdm
mit_model.eval()
size = len(mit_test_loader.dataset)
num_batches = len(mit_test_loader)
test_loss = 0
correct = 0
with torch.no_grad():
    print('Test------')
    for X, y in tqdm(mit_test_loader):

        X = X.to(device)
        pred = mit_model(X)

        label = y.to(device).squeeze(1)

        test_loss += loss_fn(pred, label).item()

        correct += (pred.argmax(1) == label).type(torch.float).sum().item()

    test_loss /= num_batches
    correct /= size

    print(f"""Test Error:
    Accuracy: {(100*correct)}%
    Avg loss: {test_loss}
    """)

def eval(model, test_loader):
    model.eval()
    soft = nn.Softmax(dim=1)
    test_loss = 0
    correct = 0
    size = len(test_loader.dataset)
    num_batches = len(test_loader)
    all_list = {'conf':[], 'pred':[], 'actual':[]}
    fail_list = {'conf':[], 'pred':[], 'actual':[]}
    with torch.no_grad():
        for X, y in tqdm(test_loader):
            X = X.to(device)
            pred = model(X)

            label = y.to(device).squeeze(1)

            test_loss += loss_fn(pred, label).item()

            final_pred = pred.argmax(1)
            confidence = soft(pred)

            all_list['conf'].append(confidence.cpu())
            all_list['pred'].append(final_pred.cpu())
            all_list['actual'].append(label.cpu())

            if final_pred == label:
                correct += 1
            else:
                fail_list['pred'].append(final_pred.cpu())
                fail_list['conf'].append(confidence.cpu())
                fail_list['actual'].append(label.cpu())

    #         test_loss /= num_batches
        correct /= size

        print(f"""Test Error:
        Accuracy: {(100*correct)}%
        """)
    return correct, fail_list, all_list

mit_model = Net().to(device)
mit_model.load_state_dict(torch.load('/kaggle/input/50epoch/50_best.pth'))

from tqdm import tqdm

correct_mit, fail_mit, all_mit = eval(mit_model, mit_test_loader)

from sklearn import metrics
from torchmetrics.classification import *

def get_metrics(pred, target, conf):
    classes = [0, 1, 2, 3, 4]
    name = ['N', 'S', 'V', 'F', 'Q']

    acc = MulticlassAccuracy(num_classes=len(name), average=None)
    preci = MulticlassPrecision(num_classes=len(name), average=None)
    recall = MulticlassRecall(num_classes=len(name), average=None)
    speci = MulticlassSpecificity(num_classes=len(name), average=None)
    f1s = MulticlassF1Score(num_classes=len(name), average=None)
#     confu = torchmetrics.classification.MulticlassConfusionMatrix(num_classes=3, normalize='true')
    roc = MulticlassROC(num_classes=len(name))
    prc = MulticlassPrecisionRecallCurve(num_classes=len(name))
    aucroc = MulticlassAUROC(num_classes=len(name), average=None)
    aucprc = MulticlassAveragePrecision(num_classes=len(name), average=None)

#     target = target.squeeze()
    pred = pred.type(torch.float)
#     print(pred.shape, target.shape)
    #Accuracy
    print('Accuracy:', acc(pred, target))
    #Precision
    print('Precision:', preci(pred, target))
    #Recall
    print('Recall:', recall(pred, target))
    #Specificity
    print('Specificity:', speci(pred, target))
    #F1
    print('F1:', f1s(pred, target))



    cm = metrics.confusion_matrix(target, pred, labels=classes).astype(float)
    row_sum = cm.sum(axis=1).astype(float).reshape(len(name), 1)

    cm /= row_sum
#     cm = cm/cm.astype(float).sum(axis=1)
#     cm = cm.round(3)
    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = name)
    cm_display.plot()

#     plt.show()
    plt.savefig(f'/kaggle/working/50_confu.jpg', dpi=400)
#     print(conf.shape)
#     print(target.shape)
    conf = conf.squeeze(1)
#     conf = conf.unsqueeze(-1)
    target = target.squeeze(1)
#     print(conf.shape)
#     print(target.shape)
    #ROC
    # Compute AUC values
    aucroc.update(conf, target.type(torch.int64))
    aucroc_values = aucroc.compute()
    roc.update(conf, target.type(torch.int64))
    fpr, tpr, thresholds = roc.compute()
#     fig2, ax2 = roc.plot(score=True)
    # Plot ROC curve
    fig2, ax2 = plt.subplots()
    for i in range(len(name)):
        ax2.plot(fpr[i], tpr[i], label=f'{name[i]} AUC:{aucroc_values[i]:.3f}')
    ax2.set_xlabel('False Positive Rate')
    ax2.set_ylabel('True Positive Rate')
    ax2.set_title('Receiver Operating Characteristic (ROC) Curve')
    ax2.legend()
    ax2.grid(True)
#     fig2.show()
    fig2.savefig(f'/kaggle/working/50_ROC.jpg', dpi=400)

    #Prc
    # Compute AUC values
    aucprc.update(conf, target.type(torch.int64))
    aucprc_values = aucprc.compute()
    prc.update(conf, target.type(torch.int64))
#     fig_, ax_ = prc.plot(score=True)
#     fig_.show()
    fpr1, tpr1, thresholds1 = prc.compute()

    fig3, ax3 = plt.subplots()
    for i in range(len(name)):
        ax3.plot(fpr1[i], tpr1[i], label=f'{name[i]} AUC:{aucprc_values[i]:.3f}')
    ax3.set_xlabel('Recall')
    ax3.set_ylabel('Precision')
    ax3.set_title('Precision Recall Curve')
    ax3.legend()
    ax3.grid(True)
#     fig3.show()
    fig3.savefig(f'/kaggle/working/50_PRC.jpg', dpi=400)

get_metrics(torch.stack(all_mit['pred']), torch.stack(all_mit['actual']), torch.stack(all_mit['conf']))