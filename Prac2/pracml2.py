# -*- coding: utf-8 -*-
"""PracML2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qkjjqF3XGkXIeAFfpvkcxRBFdReerSGu

# Required package
"""

!pip install ultralytics -q
from ultralytics import YOLO

"""# Get data"""

!curl -o test_set.zip https://zenodo.org/records/1327317/files/test_set.zip?download=1 -o test_set_pixel_size.csv https://zenodo.org/records/1327317/files/test_set_pixel_size.csv?download=1 -o training_set.zip https://zenodo.org/records/1327317/files/training_set.zip?download=1 -o training_set_pixel_size_and_HC.csv https://zenodo.org/records/1327317/files/training_set_pixel_size_and_HC.csv?download=1

!unzip /content/test_set.zip -d test

!unzip /content/training_set.zip -d train

"""# Data label processing"""

!pip install ultralytics -q

import torch
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from ultralytics import YOLO
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np

os.makedirs('/content/train/mask/', exist_ok=True)
os.makedirs('/content/train/annotation/', exist_ok=True)
for f in tqdm(os.listdir('/content/train/mask')):
    if 'Annotation' in f:
        mask = cv2.imread(f'/content/train/mask/{f}', 0)
        coords = np.where(mask == 255)

        # Find convex hull of those coords
        hull = np.squeeze(cv2.convexHull(np.array(coords).T))


        string = '0'
        for x, y in hull:
            string += f' {y/mask.shape[1]} {x/mask.shape[0]}'

        # Write label
        with open(f'/content/train/annotation/{f[:-15]}.txt', 'w') as label:
            label.write(string)

        # os.rename(f'/content/train/training_set/{f}', f'/content/train/mask/{f}')

!zip -r /content/image.zip /content/train/training_set

!zip -r /content/label.zip /content/train/annotation

"""# Get augmented data"""

!pip install roboflow -q

from roboflow import Roboflow
rf = Roboflow(api_key="5I8VCRULDK5oDJPGnksx")
project = rf.workspace("alonelymess").project("cocoon")
version = project.version(1)
dataset = version.download("yolov8")

"""# Training"""

model = YOLO('yolov8n-seg.pt')

with open('/content/Cocoon-1/data.yaml', 'w') as data:
    data.write(
        '''
        names:
        - 'cocoon'
        nc: 1
        roboflow:
        license: CC BY 4.0
        project: cocoon
        url: https://universe.roboflow.com/alonelymess/cocoon/dataset/1
        version: 1
        workspace: alonelymess
        path: /content/Cocoon-1
        test: test/images
        train: train/images
        val: valid/images

        '''
    )

result = model.train(data='/content/Cocoon-1/data.yaml', batch=64)

"""# Inference"""

import matplotlib.pyplot as plt
import cv2
import os
import numpy as np

model = YOLO('/content/best.pt')

plt.imshow(img)

for image_name in os.listdir('/content/test/test_set')[:10]:
    img = cv2.imread(f'/content/test/test_set/{image_name}')
    results = model.predict(img)[0]

    color_dict = {
        0: (0, 0, 255)
    }

    # Draw bbox
    for cat, score, mask in zip(results.boxes.cls, results.boxes.conf, results.masks.xy):
        mask = mask.reshape(-1, 1, 2)
        img = cv2.polylines(img, np.int32([mask]), isClosed=True, color = color_dict[cat.item()], thickness=2)
        # print(cat, score)
        # img = cv2.putText(img, f'{results.names[cat.item()]}', (mask[0][0][0], mask[0][0][1] + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

    plt.imshow(img)
    plt.show()